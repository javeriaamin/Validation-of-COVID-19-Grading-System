import numpy as np
import os
import cv2
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate, BatchNormalization, ReLU, Input, Dense, Flatten
from tensorflow.keras.applications import ResNet18
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from scipy.stats import entropy

# ---------------- PREPROCESSING ---------------- #
def preprocess_ct_images(ct_path, img_size=(256, 256)):
    axial_images = []
    coronal_images = []
    sagittal_images = []
    
    for img_name in os.listdir(ct_path):
        img = cv2.imread(os.path.join(ct_path, img_name), cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, img_size) / 255.0  # Normalize
        
        if "axial" in img_name:
            axial_images.append(img)
        elif "coronal" in img_name:
            coronal_images.append(img)
        elif "sagittal" in img_name:
            sagittal_images.append(img)

    return np.array(axial_images), np.array(coronal_images), np.array(sagittal_images)

def compute_volumetric_scores(images):
    scores = []
    for img in images:
        score = np.sum(img) / (img.shape[0] * img.shape[1])  # Compute intensity score
        scores.append(score)
    return np.array(scores)

def assign_severity_labels(scores):
    labels = []
    for score in scores:
        if score < 0.3:
            labels.append("Healthy")
        elif score < 0.6:
            labels.append("Mild")
        else:
            labels.append("Moderate")
    return np.array(labels)

# ---------------- FEATURE EXTRACTION ---------------- #
def extract_features(images):
    base_model = ResNet18(weights="imagenet", include_top=False, input_shape=(256, 256, 3))
    model = Model(inputs=base_model.input, outputs=base_model.get_layer("avg_pool").output)
    
    images = np.expand_dims(images, axis=-1)
    features = model.predict(images)
    features = features.reshape(features.shape[0], -1)  # Flatten
    return features

# ---------------- FEATURE SELECTION (HHO) ---------------- #
def hho_feature_selection(features, num_selected=446):
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)
    
    pca = PCA(n_components=num_selected)
    selected_features = pca.fit_transform(features_scaled)
    
    return selected_features

# ---------------- CLASSIFICATION ---------------- #
def classify_features(features, labels):
    clf = GaussianNB()
    clf.fit(features, labels)
    return clf

# ---------------- SEGMENTATION MODEL (U-NET) ---------------- #
def build_unet(input_shape=(256, 256, 1), filters=16, dropout_rate=0.05):
    inputs = Input(input_shape)

    # Encoder
    c1 = Conv2D(filters, (3, 3), activation=None, padding="same")(inputs)
    c1 = BatchNormalization()(c1)
    c1 = ReLU()(c1)
    c1 = Dropout(dropout_rate)(c1)
    c1 = Conv2D(filters, (3, 3), activation=None, padding="same")(c1)
    c1 = BatchNormalization()(c1)
    c1 = ReLU()(c1)
    p1 = MaxPooling2D((2, 2))(c1)

    c2 = Conv2D(filters * 2, (3, 3), activation=None, padding="same")(p1)
    c2 = BatchNormalization()(c2)
    c2 = ReLU()(c2)
    c2 = Dropout(dropout_rate)(c2)
    c2 = Conv2D(filters * 2, (3, 3), activation=None, padding="same")(c2)
    c2 = BatchNormalization()(c2)
    c2 = ReLU()(c2)
    p2 = MaxPooling2D((2, 2))(c2)

    # Bottleneck
    c3 = Conv2D(filters * 4, (3, 3), activation=None, padding="same")(p2)
    c3 = BatchNormalization()(c3)
    c3 = ReLU()(c3)
    c3 = Dropout(dropout_rate)(c3)
    c3 = Conv2D(filters * 4, (3, 3), activation=None, padding="same")(c3)
    c3 = BatchNormalization()(c3)
    c3 = ReLU()(c3)

    # Decoder
    u4 = Conv2DTranspose(filters * 2, (2, 2), strides=(2, 2), padding="same")(c3)
    u4 = concatenate([u4, c2])
    c4 = Conv2D(filters * 2, (3, 3), activation=None, padding="same")(u4)
    c4 = BatchNormalization()(c4)
    c4 = ReLU()(c4)
    c4 = Dropout(dropout_rate)(c4)
    c4 = Conv2D(filters * 2, (3, 3), activation=None, padding="same")(c4)
    c4 = BatchNormalization()(c4)
    c4 = ReLU()(c4)

    u5 = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding="same")(c4)
    u5 = concatenate([u5, c1])
    c5 = Conv2D(filters, (3, 3), activation=None, padding="same")(u5)
    c5 = BatchNormalization()(c5)
    c5 = ReLU()(c5)
    c5 = Dropout(dropout_rate)(c5)
    c5 = Conv2D(filters, (3, 3), activation=None, padding="same")(c5)
    c5 = BatchNormalization()(c5)
    c5 = ReLU()(c5)

    outputs = Conv2D(1, (1, 1), activation="sigmoid")(c5)

    model = Model(inputs, outputs)
    return model

# ---------------- TRAINING SEGMENTATION MODEL ---------------- #
def train_segmentation_model(image_path, mask_path):
    images, masks = preprocess_ct_images(image_path)

    train_datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, horizontal_flip=True)
    val_datagen = ImageDataGenerator()

    unet_model = build_unet()
    unet_model.compile(optimizer=Adam(learning_rate=0.001), loss=BinaryCrossentropy(), metrics=["accuracy"])

    history = unet_model.fit(
        train_datagen.flow(images, masks, batch_size=8),
        validation_data=val_datagen.flow(images, masks, batch_size=8),
        epochs=100
    )

    unet_model.save("unet_ct_segmentation.h5")
    return unet_model

# ---------------- EXECUTION PIPELINE ---------------- #
# Load CT slices
image_path = "/path/to/ct_slices"
axial_images, coronal_images, sagittal_images = preprocess_ct_images(image_path)

# Compute severity scores
scores = compute_volumetric_scores(axial_images)
labels = assign_severity_labels(scores)

# Extract features using ResNet-18
features = extract_features(axial_images)

# Select features using HHO
selected_features = hho_feature_selection(features)

# Train classifier
classifier = classify_features(selected_features, labels)

# Train segmentation model
mask_path = "/path/to/masks"
segmentation_model = train_segmentation_model(image_path, mask_path)
